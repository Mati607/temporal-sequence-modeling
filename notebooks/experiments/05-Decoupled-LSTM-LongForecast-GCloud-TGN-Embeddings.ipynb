{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MJouDrUr44kn",
      "metadata": {
        "id": "MJouDrUr44kn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722910991032,
          "user_tz": 240,
          "elapsed": 3761,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780a3e3d",
      "metadata": {
        "id": "780a3e3d"
      },
      "source": [
        "## Loading edge files with a percentile threshold on the edge weights. Higher percentile extracts stronger relations. This parameter can be adjusted to control the strength of trends that we want to predict for future."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(year, data_dir, percentile=0.9):\n",
        "    edges = pd.read_parquet(f'{data_dir}/{year}/{year}_edges.parquet', engine='pyarrow')\n",
        "    nodes = pd.read_parquet(f'{data_dir}/{year}/{year}_nodes.parquet', engine='pyarrow')\n",
        "    weight_threshold = edges['weight'].quantile(percentile)\n",
        "    filtered_edges = edges[edges['weight'] >= weight_threshold]\n",
        "    return filtered_edges, nodes\n",
        "\n",
        "data_dir = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/new_parquet_data\"\n",
        "years = range(1980, 2024)\n",
        "\n",
        "all_node_ids = set()\n",
        "id_to_label = {}\n",
        "for i in years:\n",
        "    _, n = load_data(i, data_dir)\n",
        "    all_node_ids = all_node_ids.union(set(n['node_id'].tolist()))\n",
        "    keys, vals = n['node_id'].tolist(), n['node_label'].tolist()\n",
        "    entries = {key: value for key, value in zip(keys, vals)}\n",
        "    id_to_label.update(entries)\n",
        "\n",
        "node_ids = sorted(list(all_node_ids))\n",
        "node_id_to_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
        "num_of_nodes = len(node_ids)\n",
        "trends = []\n",
        "\n",
        "for year in years:\n",
        "    edges, _ = load_data(year, data_dir)\n",
        "    edge_index = np.array([edges['source_id'].map(node_id_to_index).values,\n",
        "                           edges['destination_id'].map(node_id_to_index).values])\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "    trend = Data(edge_index=edge_index)\n",
        "    trends.append(trend)"
      ],
      "metadata": {
        "id": "Cg788N1wg_Am",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911059873,
          "user_tz": 240,
          "elapsed": 68842,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "Cg788N1wg_Am",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1155e74b-3c46-46ef-b7c0-0c9e8df43564",
      "metadata": {
        "id": "1155e74b-3c46-46ef-b7c0-0c9e8df43564"
      },
      "source": [
        "## Creating an 80:20 train-test split, where the test data follows the training data in chronological order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
      "metadata": {
        "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911060030,
          "user_tz": 240,
          "elapsed": 14,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8fdf4a6f-6033-450e-8421-9092aebe154b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x_train: 24\n",
            "Size of x_test: 6\n",
            "Size of y_train: 24\n",
            "Size of y_test: 6\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "def create_sequences(data, time_step, forecast_length):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step - forecast_length + 1):\n",
        "        X.append(list(range(i,i + time_step)))\n",
        "        Y.append(data[i + time_step + forecast_length - 1])\n",
        "    return X, Y\n",
        "\n",
        "time_window = 10\n",
        "forecast_length = 5\n",
        "\n",
        "x, y = create_sequences(trends, time_window, forecast_length)\n",
        "\n",
        "split_index = int(len(x) * 0.8)\n",
        "\n",
        "x_train, x_test = copy.deepcopy(x[:split_index]), copy.deepcopy(x[split_index:])\n",
        "y_train, y_test = copy.deepcopy(y[:split_index]), copy.deepcopy(y[split_index:])\n",
        "\n",
        "print(\"Size of x_train:\", len(x_train))\n",
        "print(\"Size of x_test:\", len(x_test))\n",
        "print(\"Size of y_train:\", len(y_train))\n",
        "print(\"Size of y_test:\", len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf820c34-b62c-4619-9299-f3d3373ced0e",
      "metadata": {
        "id": "bf820c34-b62c-4619-9299-f3d3373ced0e"
      },
      "source": [
        "## Generating negative samples equal to the number of positive samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9dac0b90-096d-4529-944e-16ddca73fa56",
      "metadata": {
        "id": "9dac0b90-096d-4529-944e-16ddca73fa56",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911066984,
          "user_tz": 240,
          "elapsed": 6956,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import copy\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "def add_negative_samples(data):\n",
        "    num_pos_samples = data.edge_index.size(1)\n",
        "    num_neg_samples = num_pos_samples\n",
        "    neg_edge_index = negative_sampling(data.edge_index, num_nodes=num_of_nodes, num_neg_samples=num_neg_samples)\n",
        "    pos_weights = torch.ones(num_pos_samples, device=data.edge_index.device)\n",
        "    neg_weights = torch.zeros(num_neg_samples, device=data.edge_index.device)\n",
        "\n",
        "    data.edge_index = torch.cat([data.edge_index, neg_edge_index], dim=1)\n",
        "    data.y = torch.cat([pos_weights, neg_weights])\n",
        "\n",
        "    perm = torch.randperm(data.edge_index.size(1))\n",
        "    data.edge_index = data.edge_index[:, perm]\n",
        "    data.y = data.y[perm]\n",
        "\n",
        "    return data\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    y_train[i] = add_negative_samples(y_train[i])\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    y_test[i] = add_negative_samples(y_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4aa9fae-068c-4545-aae7-31571480e8ec",
      "metadata": {
        "id": "c4aa9fae-068c-4545-aae7-31571480e8ec"
      },
      "source": [
        "## Decoupled LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "35280b15-0848-4d71-946f-68df3bb0c601",
      "metadata": {
        "id": "35280b15-0848-4d71-946f-68df3bb0c601",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911110695,
          "user_tz": 240,
          "elapsed": 43712,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "437bbf09-db39-4106-a98e-b88a32cc4880",
      "metadata": {
        "id": "437bbf09-db39-4106-a98e-b88a32cc4880",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911110695,
          "user_tz": 240,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def get_edge_embeddings(node_embeddings, edge_index):\n",
        "    src, dst = edge_index\n",
        "    edge_features = torch.cat([node_embeddings[src], node_embeddings[dst]], dim=1)\n",
        "    return edge_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "\n",
        "def load_embeddings_from_bucket(index):\n",
        "    path = f'gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/Tgn_embeddings_d5/{1980+index}.pt'\n",
        "    fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "    with fs.open(path, 'rb') as f:\n",
        "        embeddings = torch.load(f)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "qrq9_N6w-xcU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911110695,
          "user_tz": 240,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "qrq9_N6w-xcU",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "12e9138c-dc77-4ed9-a498-dfb3f40b9747",
      "metadata": {
        "id": "12e9138c-dc77-4ed9-a498-dfb3f40b9747",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911110695,
          "user_tz": 240,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def extract_edge_embeddings(index, edge_index):\n",
        "    with torch.no_grad():\n",
        "        node_embeddings = load_embeddings_from_bucket(index)\n",
        "        edge_embeddings = get_edge_embeddings(node_embeddings, edge_index).detach().numpy()\n",
        "        return edge_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "461a7c32-381f-4dc4-a9cc-57a9832f1ba6",
      "metadata": {
        "id": "461a7c32-381f-4dc4-a9cc-57a9832f1ba6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911229711,
          "user_tz": 240,
          "elapsed": 119017,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "x_train_lstm = []\n",
        "y_train_lstm = []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "    embs = []\n",
        "    for j in range(len(x_train[i])):\n",
        "        edge_embs = extract_edge_embeddings(x_train[i][j], y_train[i].edge_index)\n",
        "        embs.append(edge_embs)\n",
        "    stacked_embs = np.stack(embs,axis=1)\n",
        "    x_train_lstm.append(stacked_embs)\n",
        "    y_train_lstm.append(y_train[i].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d50bf603-9ed2-459a-9c75-cab3b0d43a17",
      "metadata": {
        "id": "d50bf603-9ed2-459a-9c75-cab3b0d43a17",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911246703,
          "user_tz": 240,
          "elapsed": 16994,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "x_train_lstm = np.vstack(x_train_lstm)\n",
        "y_train_lstm = np.hstack(y_train_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "77120a5c-4304-44cd-a696-4d119c47df3e",
      "metadata": {
        "scrolled": true,
        "id": "77120a5c-4304-44cd-a696-4d119c47df3e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911284637,
          "user_tz": 240,
          "elapsed": 37935,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "x_test_lstm = []\n",
        "y_test_lstm = []\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    embs = []\n",
        "    for j in range(len(x_test[i])):\n",
        "        edge_embs = extract_edge_embeddings(x_test[i][j], y_test[i].edge_index)\n",
        "        embs.append(edge_embs)\n",
        "    stacked_embs = np.stack(embs,axis=1)\n",
        "    x_test_lstm.append(stacked_embs)\n",
        "    y_test_lstm.append(y_test[i].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0132c01a-e66c-41f7-b232-3921d3e3117f",
      "metadata": {
        "id": "0132c01a-e66c-41f7-b232-3921d3e3117f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722911292280,
          "user_tz": 240,
          "elapsed": 7652,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "x_test_lstm = np.vstack(x_test_lstm)\n",
        "y_test_lstm = np.hstack(y_test_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d45e2221-db5e-4753-b0e0-86d5833fde8e",
      "metadata": {
        "id": "d45e2221-db5e-4753-b0e0-86d5833fde8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a140376c-05d4-4007-a702-92cfc5e93c7e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722912644814,
          "user_tz": 240,
          "elapsed": 1352535,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "7023/7023 [==============================] - 440s 62ms/step - loss: 0.3565\n",
            "Epoch 2/3\n",
            "7023/7023 [==============================] - 432s 61ms/step - loss: 0.3305\n",
            "Epoch 3/3\n",
            "7023/7023 [==============================] - 433s 62ms/step - loss: 0.3204\n"
          ]
        }
      ],
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, return_sequences=True, input_shape=(x_train_lstm.shape[1], x_train_lstm.shape[2])))\n",
        "lstm_model.add(LSTM(50))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history = lstm_model.fit(x_train_lstm, y_train_lstm, batch_size=1024, epochs=3, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8638b629-0407-4add-884d-d52ec8e711c2",
      "metadata": {
        "id": "8638b629-0407-4add-884d-d52ec8e711c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722912784645,
          "user_tz": 240,
          "elapsed": 139833,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "09e1cff3-d52d-4ed3-91ab-40a50e637f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3287/3287 [==============================] - 116s 35ms/step\n"
          ]
        }
      ],
      "source": [
        "probs = lstm_model.predict(x_test_lstm,batch_size = 1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7d6e721c-b4a0-439f-a188-5c5c1c6cce36",
      "metadata": {
        "id": "7d6e721c-b4a0-439f-a188-5c5c1c6cce36",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722912784645,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "threshold = 0.5\n",
        "yhat = (probs > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "84fc9ab7-0caf-44e9-8aed-9c85495030c4",
      "metadata": {
        "id": "84fc9ab7-0caf-44e9-8aed-9c85495030c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722912786094,
          "user_tz": 240,
          "elapsed": 1450,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6f5906bf-2f46-4132-aed0-666d23b7d9b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 84%\n",
            "Precision: 81%\n",
            "Recall: 88%\n",
            "Presence Accuracy: 88%\n",
            "Absence Accuracy: 79%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "y_true = y_test_lstm.astype(int)\n",
        "\n",
        "presence_mask = y_true == 1\n",
        "absence_mask = y_true == 0\n",
        "\n",
        "presence_accuracy = accuracy_score(y_true[presence_mask], yhat[presence_mask])\n",
        "\n",
        "absence_accuracy = accuracy_score(y_true[absence_mask], yhat[absence_mask])\n",
        "\n",
        "total_accuracy = accuracy_score(y_true, yhat)\n",
        "precision = precision_score(y_true, yhat, zero_division=0)\n",
        "recall = recall_score(y_true, yhat, zero_division=0)\n",
        "\n",
        "total_accuracy_percentage = round(total_accuracy * 100)\n",
        "precision_percentage = round(precision * 100)\n",
        "recall_percentage = round(recall * 100)\n",
        "presence_accuracy_percentage = round(presence_accuracy * 100)\n",
        "absence_accuracy_percentage = round(absence_accuracy * 100)\n",
        "\n",
        "print(f'Overall Accuracy: {total_accuracy_percentage}%')\n",
        "print(f'Precision: {precision_percentage}%')\n",
        "print(f'Recall: {recall_percentage}%')\n",
        "print(f'Presence Accuracy: {presence_accuracy_percentage}%')\n",
        "print(f'Absence Accuracy: {absence_accuracy_percentage}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "LSTM_Decoupled__long_forcast_gcloud_TGN_embeddings.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
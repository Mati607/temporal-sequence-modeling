{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dda1c9a3-46d6-4600-b615-f6698cffce2b",
      "metadata": {
        "id": "dda1c9a3-46d6-4600-b615-f6698cffce2b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722565164663,
          "user_tz": 240,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def install_dependencies():\n",
        "    commands = [\n",
        "        \"sudo apt install unzip -y\",\n",
        "        \"pip install gdown\",\n",
        "        \"pip install torch\",\n",
        "        \"pip install torch-geometric\",\n",
        "        \"pip install numpy\",\n",
        "        \"pip install pandas\",\n",
        "        \"pip install scikit-learn\",\n",
        "        \"pip install pyarrow\",\n",
        "        \"pip install tensorflow\"\n",
        "    ]\n",
        "\n",
        "    for command in commands:\n",
        "        process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
        "        output, error = process.communicate()\n",
        "        if error:\n",
        "            print(f\"Error occurred: {error}\")\n",
        "        else:\n",
        "            print(f\"Output: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MJouDrUr44kn",
      "metadata": {
        "id": "MJouDrUr44kn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722565168534,
          "user_tz": 240,
          "elapsed": 3874,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780a3e3d",
      "metadata": {
        "id": "780a3e3d"
      },
      "source": [
        "## Loading edge files with a percentile threshold on the edge weights. Higher percentile extracts stronger relations. This parameter can be adjusted to control the strength of trends that we want to predict for future."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(year, data_dir, percentile=0.9):\n",
        "    edges = pd.read_parquet(f'{data_dir}/{year}/{year}_edges.parquet', engine='pyarrow')\n",
        "    nodes = pd.read_parquet(f'{data_dir}/{year}/{year}_nodes.parquet', engine='pyarrow')\n",
        "    weight_threshold = edges['weight'].quantile(percentile)\n",
        "    filtered_edges = edges[edges['weight'] >= weight_threshold]\n",
        "    return filtered_edges, nodes\n",
        "\n",
        "data_dir = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/new_parquet_data\"\n",
        "years = range(1980, 2024)\n",
        "\n",
        "all_node_ids = set()\n",
        "id_to_label = {}\n",
        "for i in years:\n",
        "    _, n = load_data(i, data_dir)\n",
        "    all_node_ids = all_node_ids.union(set(n['node_id'].tolist()))\n",
        "    keys, vals = n['node_id'].tolist(), n['node_label'].tolist()\n",
        "    entries = {key: value for key, value in zip(keys, vals)}\n",
        "    id_to_label.update(entries)\n",
        "\n",
        "node_ids = sorted(list(all_node_ids))\n",
        "node_id_to_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
        "num_of_nodes = len(node_ids)\n",
        "trends = []\n",
        "\n",
        "for year in years:\n",
        "    edges, _ = load_data(year, data_dir)\n",
        "    edge_index = np.array([edges['source_id'].map(node_id_to_index).values,\n",
        "                           edges['destination_id'].map(node_id_to_index).values])\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "    trend = Data(edge_index=edge_index)\n",
        "    trends.append(trend)"
      ],
      "metadata": {
        "id": "Cg788N1wg_Am"
      },
      "id": "Cg788N1wg_Am",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1155e74b-3c46-46ef-b7c0-0c9e8df43564",
      "metadata": {
        "id": "1155e74b-3c46-46ef-b7c0-0c9e8df43564"
      },
      "source": [
        "## Creating an 80:20 train-test split, where the test data follows the training data in chronological order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
      "metadata": {
        "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722359690982,
          "user_tz": 240,
          "elapsed": 161,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9cc08156-d60d-404e-ab9f-3d26496d4530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x_train: 27\n",
            "Size of x_test: 7\n",
            "Size of y_train: 27\n",
            "Size of y_test: 7\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "def create_sequences(data, time_step):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(list(range(1980+i, 1980+i + time_step)))\n",
        "        Y.append(1980+i + time_step)\n",
        "    return X, Y\n",
        "\n",
        "time_window = 10\n",
        "\n",
        "x, y = create_sequences(trends, time_window)\n",
        "\n",
        "split_index = int(len(x) * 0.8)\n",
        "\n",
        "x_train, x_test = copy.deepcopy(x[:split_index]), copy.deepcopy(x[split_index:])\n",
        "y_train, y_test = copy.deepcopy(y[:split_index]), copy.deepcopy(y[split_index:])\n",
        "\n",
        "print(\"Size of x_train:\", len(x_train))\n",
        "print(\"Size of x_test:\", len(x_test))\n",
        "print(\"Size of y_train:\", len(y_train))\n",
        "print(\"Size of y_test:\", len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBgyVrEcoDDi",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722359691849,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "77d816f4-143b-4e66-f99c-135fbbdef9e2"
      },
      "id": "NBgyVrEcoDDi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989], [1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990], [1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991], [1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992], [1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993], [1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994], [1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995], [1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996], [1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997], [1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998], [1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999], [1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000], [1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001], [1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002], [1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003], [1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004], [1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005], [1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006], [1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007], [1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008], [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009], [2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010], [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011], [2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012], [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013], [2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014], [2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMYG4deTofx3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722359692154,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e8eac9b5-b373-491a-f59a-912013ce52ac"
      },
      "id": "CMYG4deTofx3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz6w_Ri3omCr",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722359693115,
          "user_tz": 240,
          "elapsed": 150,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1878c414-e4f4-4876-f0f4-d2a750a78ac5"
      },
      "id": "wz6w_Ri3omCr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2017, 2018, 2019, 2020, 2021, 2022, 2023]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf820c34-b62c-4619-9299-f3d3373ced0e",
      "metadata": {
        "id": "bf820c34-b62c-4619-9299-f3d3373ced0e"
      },
      "source": [
        "## Generating negative samples equal to the number of positive samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dac0b90-096d-4529-944e-16ddca73fa56",
      "metadata": {
        "id": "9dac0b90-096d-4529-944e-16ddca73fa56"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import copy\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "def add_negative_samples(data):\n",
        "    num_pos_samples = data.edge_index.size(1)\n",
        "    num_neg_samples = num_pos_samples\n",
        "    neg_edge_index = negative_sampling(data.edge_index, num_nodes=num_of_nodes, num_neg_samples=num_neg_samples)\n",
        "    pos_weights = torch.ones(num_pos_samples, device=data.edge_index.device)\n",
        "    neg_weights = torch.zeros(num_neg_samples, device=data.edge_index.device)\n",
        "\n",
        "    data.edge_index = torch.cat([data.edge_index, neg_edge_index], dim=1)\n",
        "    data.y = torch.cat([pos_weights, neg_weights])\n",
        "\n",
        "    perm = torch.randperm(data.edge_index.size(1))\n",
        "    data.edge_index = data.edge_index[:, perm]\n",
        "    data.y = data.y[perm]\n",
        "\n",
        "    return data\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    y_train[i] = add_negative_samples(y_train[i])\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    y_test[i] = add_negative_samples(y_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4aa9fae-068c-4545-aae7-31571480e8ec",
      "metadata": {
        "id": "c4aa9fae-068c-4545-aae7-31571480e8ec"
      },
      "source": [
        "## Decoupled LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35280b15-0848-4d71-946f-68df3bb0c601",
      "metadata": {
        "id": "35280b15-0848-4d71-946f-68df3bb0c601",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722565171365,
          "user_tz": 240,
          "elapsed": 2832,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "437bbf09-db39-4106-a98e-b88a32cc4880",
      "metadata": {
        "id": "437bbf09-db39-4106-a98e-b88a32cc4880",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722565171365,
          "user_tz": 240,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def get_edge_embeddings(node_embeddings, edge_index):\n",
        "    src, dst = edge_index\n",
        "    edge_features = torch.cat([node_embeddings[src], node_embeddings[dst]], dim=1)\n",
        "    return edge_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gcsfs\n",
        "\n",
        "def load_embeddings_from_bucket(index):\n",
        "    path = f'gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/Tgn_embeddings_d5/{1980+index}.pt'\n",
        "    fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "    with fs.open(path, 'rb') as f:\n",
        "        embeddings = torch.load(f)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "qrq9_N6w-xcU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722565189293,
          "user_tz": 240,
          "elapsed": 196,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "qrq9_N6w-xcU",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e9138c-dc77-4ed9-a498-dfb3f40b9747",
      "metadata": {
        "id": "12e9138c-dc77-4ed9-a498-dfb3f40b9747"
      },
      "outputs": [],
      "source": [
        "def extract_edge_embeddings(index, edge_index):\n",
        "    with torch.no_grad():\n",
        "        node_embeddings = load_embeddings_from_bucket(index)\n",
        "        edge_embeddings = get_edge_embeddings(node_embeddings, edge_index).detach().numpy()\n",
        "        return edge_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461a7c32-381f-4dc4-a9cc-57a9832f1ba6",
      "metadata": {
        "id": "461a7c32-381f-4dc4-a9cc-57a9832f1ba6"
      },
      "outputs": [],
      "source": [
        "x_train_lstm = []\n",
        "y_train_lstm = []\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "    embs = []\n",
        "    for j in range(len(x_train[i])):\n",
        "        edge_embs = extract_edge_embeddings(x_train[i][j], y_train[i].edge_index)\n",
        "        embs.append(edge_embs)\n",
        "    stacked_embs = np.stack(embs,axis=1)\n",
        "    x_train_lstm.append(stacked_embs)\n",
        "    y_train_lstm.append(y_train[i].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d50bf603-9ed2-459a-9c75-cab3b0d43a17",
      "metadata": {
        "id": "d50bf603-9ed2-459a-9c75-cab3b0d43a17"
      },
      "outputs": [],
      "source": [
        "x_train_lstm = np.vstack(x_train_lstm)\n",
        "y_train_lstm = np.hstack(y_train_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77120a5c-4304-44cd-a696-4d119c47df3e",
      "metadata": {
        "scrolled": true,
        "id": "77120a5c-4304-44cd-a696-4d119c47df3e"
      },
      "outputs": [],
      "source": [
        "x_test_lstm = []\n",
        "y_test_lstm = []\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    embs = []\n",
        "    for j in range(len(x_test[i])):\n",
        "        edge_embs = extract_edge_embeddings(x_test[i][j], y_test[i].edge_index)\n",
        "        embs.append(edge_embs)\n",
        "    stacked_embs = np.stack(embs,axis=1)\n",
        "    x_test_lstm.append(stacked_embs)\n",
        "    y_test_lstm.append(y_test[i].y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0132c01a-e66c-41f7-b232-3921d3e3117f",
      "metadata": {
        "id": "0132c01a-e66c-41f7-b232-3921d3e3117f"
      },
      "outputs": [],
      "source": [
        "x_test_lstm = np.vstack(x_test_lstm)\n",
        "y_test_lstm = np.hstack(y_test_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45e2221-db5e-4753-b0e0-86d5833fde8e",
      "metadata": {
        "id": "d45e2221-db5e-4753-b0e0-86d5833fde8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721830701966,
          "user_tz": 240,
          "elapsed": 1043131,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "8181cbce-8f16-4c34-82dc-5c0af9f1c589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "6586/6586 [==============================] - 338s 51ms/step - loss: 0.3044\n",
            "Epoch 2/3\n",
            "6586/6586 [==============================] - 331s 50ms/step - loss: 0.2746\n",
            "Epoch 3/3\n",
            "6586/6586 [==============================] - 334s 51ms/step - loss: 0.2628\n"
          ]
        }
      ],
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, return_sequences=True, input_shape=(x_train_lstm.shape[1], x_train_lstm.shape[2])))\n",
        "lstm_model.add(LSTM(50))\n",
        "lstm_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "history = lstm_model.fit(x_train_lstm, y_train_lstm, batch_size=1024, epochs=3, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8638b629-0407-4add-884d-d52ec8e711c2",
      "metadata": {
        "id": "8638b629-0407-4add-884d-d52ec8e711c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721830824453,
          "user_tz": 240,
          "elapsed": 122489,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "860b30d2-f8bf-41a4-c260-83f9b880575d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3654/3654 [==============================] - 103s 28ms/step\n"
          ]
        }
      ],
      "source": [
        "probs = lstm_model.predict(x_test_lstm,batch_size = 1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d6e721c-b4a0-439f-a188-5c5c1c6cce36",
      "metadata": {
        "id": "7d6e721c-b4a0-439f-a188-5c5c1c6cce36"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "threshold = 0.5\n",
        "yhat = (probs > threshold).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84fc9ab7-0caf-44e9-8aed-9c85495030c4",
      "metadata": {
        "id": "84fc9ab7-0caf-44e9-8aed-9c85495030c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721830826256,
          "user_tz": 240,
          "elapsed": 1804,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ba752b6d-eff5-496d-b03d-19807cd0717b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 86%\n",
            "Precision: 82%\n",
            "Recall: 91%\n",
            "Presence Accuracy: 91%\n",
            "Absence Accuracy: 80%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "y_true = y_test_lstm.astype(int)\n",
        "\n",
        "presence_mask = y_true == 1\n",
        "absence_mask = y_true == 0\n",
        "\n",
        "presence_accuracy = accuracy_score(y_true[presence_mask], yhat[presence_mask])\n",
        "\n",
        "absence_accuracy = accuracy_score(y_true[absence_mask], yhat[absence_mask])\n",
        "\n",
        "total_accuracy = accuracy_score(y_true, yhat)\n",
        "precision = precision_score(y_true, yhat, zero_division=0)\n",
        "recall = recall_score(y_true, yhat, zero_division=0)\n",
        "\n",
        "total_accuracy_percentage = round(total_accuracy * 100)\n",
        "precision_percentage = round(precision * 100)\n",
        "recall_percentage = round(recall * 100)\n",
        "presence_accuracy_percentage = round(presence_accuracy * 100)\n",
        "absence_accuracy_percentage = round(absence_accuracy * 100)\n",
        "\n",
        "print(f'Overall Accuracy: {total_accuracy_percentage}%')\n",
        "print(f'Precision: {precision_percentage}%')\n",
        "print(f'Recall: {recall_percentage}%')\n",
        "print(f'Presence Accuracy: {presence_accuracy_percentage}%')\n",
        "print(f'Absence Accuracy: {absence_accuracy_percentage}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "LSTM_Decoupled_gcloud_TGN_embeddings.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
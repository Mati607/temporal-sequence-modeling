{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from corvic.model import Source, Column, feature_type, FeatureView, FeatureViewEdgeTableMetadata\n",
        "from corvic import system_sqlite\n",
        "from corvic import system\n",
        "from pathlib import Path\n",
        "import tempfile"
      ],
      "metadata": {
        "id": "rRmEBuLVZ-eX",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722023865594,
          "user_tz": 240,
          "elapsed": 8473,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "rRmEBuLVZ-eX",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TemporalDataHandler import TemporalDataHandler\n",
        "from TGNEncoder import TGNEncoder"
      ],
      "metadata": {
        "id": "xQ7etAsuGy7A",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1722023902751,
          "user_tz": 240,
          "elapsed": 35783,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "xQ7etAsuGy7A",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from corvic.model import FeatureView, FeatureViewEdgeTableMetadata\n",
        "import polars as pl\n",
        "\n",
        "import tempfile\n",
        "\n",
        "import deepgnn.graph_engine.snark.convert as convert\n",
        "from deepgnn.graph_engine.snark.decoders import EdgeListDecoder\n",
        "\n",
        "from deepgnn.graph_engine.snark.distributed import Server, Client as DistributedClient\n",
        "\n",
        "\n",
        "class DeepGnnGraph:\n",
        "  def __init__(self, feature_view:FeatureView, feature_column:str, compute_server_url:str, random_feature_dim:int,  partitions:int = 2):\n",
        "      self.feature_view = feature_view\n",
        "      self.partitions = partitions\n",
        "      self.graph_engine = compute_server_url\n",
        "      self.random_feature_dim = random_feature_dim\n",
        "      self.feature_column_name = feature_column\n",
        "\n",
        "  def _edge_generator(self):\n",
        "      table = self.feature_view.output_edge_tables()[0]\n",
        "      edge_table_info = table.get_typed_metadata(FeatureViewEdgeTableMetadata)\n",
        "      batch = list(table.to_polars().unwrap_or_raise())[0]\n",
        "      df = batch.with_columns(\n",
        "          pl.col(edge_table_info.start_source_column_name).alias(\"start_id\"),\n",
        "          pl.lit(edge_table_info.start_source_name).alias(\"start_source\"),\n",
        "          pl.col(edge_table_info.end_source_column_name).alias(\"end_id\"),\n",
        "          pl.lit(edge_table_info.end_source_name).alias(\"end_source\"),\n",
        "      ).select(\"start_id\", \"end_id\")\n",
        "      edges_dict = df.to_dict(as_series=False)\n",
        "      return [(start_id, 'None', end_id, 1) for start_id, end_id in zip(edges_dict['start_id'], edges_dict['end_id'])]\n",
        "\n",
        "  def _node_generator(self):\n",
        "    nodes = {}\n",
        "    for nodes_source in self.feature_view.sources:\n",
        "        if nodes_source.table.schema.get_primary_key() is not None:\n",
        "            nodes_df = pl.concat(nodes_source.table.to_polars().unwrap_or_raise())\n",
        "            nodes_dict = nodes_df.to_dict(as_series=False)\n",
        "            id_column = nodes_source.table.schema.get_primary_key().name\n",
        "            if self.feature_column_name is None:\n",
        "                print(\"Feature column not specified, using random features.\")\n",
        "                for entity_id in nodes_dict[id_column]:\n",
        "                    nodes[entity_id] = ('None', 1, {'float32': np.random.rand(self.random_feature_dim).astype('float32')})\n",
        "            else:\n",
        "                for entity_id, features in zip(nodes_dict[id_column], nodes_dict[self.feature_column_name]):\n",
        "                    nodes[entity_id] = ('None', 1, {'float32': features})\n",
        "    return nodes\n",
        "\n",
        "  def _to_deepgnn_format(self, delimiter=\",\"):\n",
        "    nodes, edges = self._node_generator(), self._edge_generator()\n",
        "    node_id_map = {node_id: idx for idx, node_id in enumerate(nodes.keys())}\n",
        "    node_type_map = {node_type: idx for idx, node_type in enumerate(set(node_info[0] for node_info in nodes.values()))}\n",
        "    edge_label_map = {edge_label: idx for idx, edge_label in enumerate(set(edge[1] for edge in edges))}\n",
        "\n",
        "    def format_features(features):\n",
        "        formatted = []\n",
        "        for dtype, values in features.items():\n",
        "            formatted.append(f\"{dtype},{len(values)},{','.join(map(str, values))}\")\n",
        "        return delimiter.join(formatted)\n",
        "\n",
        "    def format_node(node_id, node_info):\n",
        "        mapped_node_id = node_id_map[node_id]\n",
        "        mapped_node_type = node_type_map[node_info[0]]\n",
        "        node_weight = node_info[1]\n",
        "        features = node_info[2]\n",
        "        formatted_features = format_features(features)\n",
        "        return f\"{mapped_node_id},-1,{mapped_node_type},{node_weight},{formatted_features}\"\n",
        "\n",
        "    def format_edge(edge_info):\n",
        "        src, edge_label, dst, edge_weight = edge_info\n",
        "        mapped_src = node_id_map[src]\n",
        "        mapped_dst = node_id_map[dst]\n",
        "        mapped_edge_label = edge_label_map[edge_label]\n",
        "        return f\"{mapped_src},{mapped_edge_label},{mapped_dst},{edge_weight}\"\n",
        "\n",
        "    node_lines = [format_node(node_id, info) for node_id, info in nodes.items()]\n",
        "    edge_lines = [format_edge(info) for info in edges]\n",
        "    all_lines = sorted(node_lines + edge_lines, key=lambda x: int(x.split(delimiter)[0]))\n",
        "    return \"\\n\".join(all_lines)\n",
        "\n",
        "  def create(self,working_dir):\n",
        "    edgelist = self._to_deepgnn_format()\n",
        "    with tempfile.NamedTemporaryFile(delete=True) as temp_file:\n",
        "        temp_file.write(edgelist.encode())\n",
        "        temp_file.flush()\n",
        "\n",
        "        edge_decoder = EdgeListDecoder()\n",
        "        convert.MultiWorkersConverter(\n",
        "            graph_path=temp_file.name,\n",
        "            partition_count=self.partitions,\n",
        "            output_dir=working_dir.name,\n",
        "            decoder=edge_decoder,\n",
        "        ).convert()\n",
        "\n",
        "    s = Server(self.graph_engine, working_dir.name, 0, 1)\n",
        "    graph = DistributedClient([self.graph_engine])\n",
        "    return graph"
      ],
      "metadata": {
        "id": "kmEcSzvhlbuY"
      },
      "id": "kmEcSzvhlbuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from deepgnn.graph_engine import SamplingStrategy\n",
        "\n",
        "\n",
        "\n",
        "from deepgnn.graph_engine.graph_ops import sub_graph\n",
        "\n",
        "from torch.utils.data import IterableDataset\n",
        "\n",
        "class Sampler(IterableDataset):\n",
        "    def __init__(self, batch_size: int, hops: int, graph, feature_dim: int):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.hops = hops\n",
        "        self.graph = graph\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "    def __iter__(self):\n",
        "        return map(self.query, range(0, self.graph.node_count(np.array([0], dtype=np.int32)), self.batch_size))\n",
        "\n",
        "    def _sampler(self,seed):\n",
        "        nodes, edge_index, _ = sub_graph(self.graph, seed, np.array([0], dtype=np.int32), num_hops=self.hops, return_edges=True)\n",
        "        edge_index = edge_index.transpose()\n",
        "        return nodes, edge_index\n",
        "\n",
        "    def query(self, batch_id: int) -> tuple:\n",
        "        seed = self.graph.sample_nodes(self.batch_size, np.array([0], dtype=np.int32), strategy=SamplingStrategy.Random)\n",
        "        seed, inverse_seed = np.unique(seed, return_inverse=True)\n",
        "        nodes, edge_index = self._sampler(seed)\n",
        "        feats = self.graph.node_features(nodes, np.array([[0, self.feature_dim]], dtype=np.int32), np.float32)\n",
        "        return torch.tensor(feats, dtype=torch.float), torch.tensor(edge_index, dtype=torch.long)"
      ],
      "metadata": {
        "id": "LOXt-vVDmEu1"
      },
      "id": "LOXt-vVDmEu1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "\n",
        "def construct_sources(client: system.Client):\n",
        "    node_df = pl.read_parquet(f\"{path}/nodes.parquet\").unique()\n",
        "    edge_df = pl.read_parquet(f\"{path}/edges.parquet\").unique()\n",
        "\n",
        "    nodes_source = (\n",
        "            Source.from_polars(\"concepts\", node_df, client)\n",
        "            .with_feature_types(\n",
        "                {\n",
        "                    \"node_id\": feature_type.primary_key(),\n",
        "                    \"node_label\": feature_type.text(),\n",
        "                }\n",
        "            ).as_dimension_table()\n",
        "        ).register()\n",
        "\n",
        "    edges_source = (\n",
        "            Source.from_polars(\"trends\", edge_df, client)\n",
        "            .with_feature_types(\n",
        "                {\n",
        "                    \"source_id\": feature_type.foreign_key(nodes_source.id),\n",
        "                    \"destination_id\": feature_type.foreign_key(nodes_source.id),\n",
        "                    \"weight\": feature_type.numerical(),\n",
        "                    \"year\": feature_type.numerical(),\n",
        "                }\n",
        "            )\n",
        "            .as_fact_table()\n",
        "        ).register()\n",
        "\n",
        "    return nodes_source, edges_source"
      ],
      "metadata": {
        "id": "opRyGDJfYNQh"
      },
      "id": "opRyGDJfYNQh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/feature_view_data\"\n",
        "\n",
        "with tempfile.TemporaryDirectory() as tdir:\n",
        "    client = system_sqlite.Client(Path(tdir) / \"corvic_data.sqlite3\")\n",
        "    nodes_source, edges_source = construct_sources(client)"
      ],
      "metadata": {
        "id": "9oUpR17_zwo_"
      },
      "id": "9oUpR17_zwo_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "handler = TemporalDataHandler(nodes_source, edges_source, 1980, 2023, 1, client)"
      ],
      "metadata": {
        "id": "QadD-quIl44p"
      },
      "id": "QadD-quIl44p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn = TGNEncoder(handler,10)"
      ],
      "metadata": {
        "id": "E-esJJEl2mhX"
      },
      "id": "E-esJJEl2mhX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn.train()"
      ],
      "metadata": {
        "id": "zTUdAIpQ2qZ_"
      },
      "id": "zTUdAIpQ2qZ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = gnn.generate_node_embeddings()"
      ],
      "metadata": {
        "id": "26nj8yYIL3S-"
      },
      "id": "26nj8yYIL3S-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import io\n",
        "from google.cloud import storage\n",
        "\n",
        "def upload_tensor_to_gcs(tensor, bucket_name, destination_blob_name):\n",
        "    \"\"\"Uploads a tensor to the GCS bucket.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    buffer = io.BytesIO()\n",
        "    torch.save(tensor, buffer)\n",
        "    buffer.seek(0)\n",
        "\n",
        "    blob.upload_from_file(buffer, content_type='application/octet-stream')\n",
        "\n",
        "bucket_name = 'datasets-dev-ded86f66'\n",
        "prefix = 'benchmarks/scientific_trend_prediction/Tgn_embeddings'\n",
        "\n",
        "for year in range(len(embeddings)):\n",
        "    node_embeddings = embeddings[year]\n",
        "    gcs_file = f'{prefix}/{1980 + year}.pt'\n",
        "\n",
        "    upload_tensor_to_gcs(node_embeddings, bucket_name, gcs_file)\n",
        "\n",
        "    print(f'Saved embeddings for year {1980 + year} to {gcs_file}')"
      ],
      "metadata": {
        "id": "Cng7ySr0JxNM"
      },
      "id": "Cng7ySr0JxNM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Refactored_generte_TGN_embeddings_with_Corvic_feature_views.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
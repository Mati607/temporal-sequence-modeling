{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e1148181-c72b-4f7c-9463-fb63fefe3f12",
      "metadata": {
        "id": "e1148181-c72b-4f7c-9463-fb63fefe3f12"
      },
      "source": [
        "# Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda1c9a3-46d6-4600-b615-f6698cffce2b",
      "metadata": {
        "id": "dda1c9a3-46d6-4600-b615-f6698cffce2b"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def install_dependencies():\n",
        "    commands = [\n",
        "        \"sudo apt install unzip -y\",\n",
        "        \"pip install gdown\",\n",
        "        \"pip install torch\",\n",
        "        \"pip install torch-geometric\",\n",
        "        \"pip install numpy\",\n",
        "        \"pip install pandas\",\n",
        "        \"pip install scikit-learn\",\n",
        "        \"pip install xxhash\",\n",
        "        \"pip install pyarrow\",\n",
        "        \"pip install tensorflow\"\n",
        "    ]\n",
        "\n",
        "    for command in commands:\n",
        "        process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
        "        output, error = process.communicate()\n",
        "        if error:\n",
        "            print(f\"Error occurred: {error}\")\n",
        "        else:\n",
        "            print(f\"Output: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MJouDrUr44kn",
      "metadata": {
        "id": "MJouDrUr44kn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import xxhash"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780a3e3d",
      "metadata": {
        "id": "780a3e3d"
      },
      "source": [
        "## Loading edge files with a percentile threshold on the edge weights. Higher percentile extracts stronger relations. This parameter can be adjusted to control the strength of trends that we want to predict for future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pLW3HgyQ2CFP",
      "metadata": {
        "id": "pLW3HgyQ2CFP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(year, data_dir, percentile=0.9):\n",
        "    edges = pd.read_parquet(f'{data_dir}/{year}/{year}_edges.parquet', engine='pyarrow')\n",
        "    nodes = pd.read_parquet(f'{data_dir}/{year}/{year}_nodes.parquet', engine='pyarrow')\n",
        "    weight_threshold = edges['weight'].quantile(percentile)\n",
        "    filtered_edges = edges[edges['weight'] >= weight_threshold]\n",
        "    return filtered_edges, nodes\n",
        "\n",
        "data_dir = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/new_parquet_data\"\n",
        "years = range(1980, 2024)\n",
        "\n",
        "_, nodes = load_data(1980, data_dir)\n",
        "all_node_ids = nodes['node_id'].tolist()\n",
        "\n",
        "all_node_ids = set()\n",
        "id_to_label = {}\n",
        "for i in years:\n",
        "    _, n = load_data(i, data_dir)\n",
        "    all_node_ids = all_node_ids.union(set(n['node_id'].tolist()))\n",
        "    keys , vals = n['node_id'].tolist() , n['node_label'].tolist()\n",
        "    entries = {key: value for key, value in zip(keys, vals)}\n",
        "    id_to_label.update(entries)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e3451f",
      "metadata": {
        "id": "a7e3451f"
      },
      "source": [
        "# Constructing temporal graph sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d190d8de-7f46-4439-a14b-d516e5ea3c7e",
      "metadata": {
        "id": "d190d8de-7f46-4439-a14b-d516e5ea3c7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "\n",
        "def featurizer(edges, node_ids, id_to_label):\n",
        "    label_order = ['phenotype', 'gene', 'compound']\n",
        "    label_to_index = {label: i for i, label in enumerate(label_order)}\n",
        "\n",
        "    node_features = np.zeros((len(node_ids), 3), dtype=float)\n",
        "    out_degree_count = {node: {label: 0 for label in label_order} for node in node_ids}\n",
        "\n",
        "    for src, dest in zip(edges['source_id'], edges['destination_id']):\n",
        "        dest_label = id_to_label[dest]\n",
        "        out_degree_count[src][dest_label] += 1\n",
        "\n",
        "    for i, node in enumerate(node_ids):\n",
        "        node_feature_vector = [out_degree_count[node][label] for label in label_order]\n",
        "        node_features[i] = node_feature_vector\n",
        "\n",
        "    return torch.tensor(node_features, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64acd77b-7d6a-4ee6-ad00-a3068e73f234",
      "metadata": {
        "id": "64acd77b-7d6a-4ee6-ad00-a3068e73f234"
      },
      "outputs": [],
      "source": [
        "node_ids = list(all_node_ids)\n",
        "node_id_to_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
        "\n",
        "graphs = []\n",
        "\n",
        "for year in years:\n",
        "    edges, _ = load_data(year, data_dir)\n",
        "    node_feature = featurizer(edges, node_ids, id_to_label)\n",
        "    edge_index = np.array([edges['source_id'].map(node_id_to_index).values,\n",
        "                           edges['destination_id'].map(node_id_to_index).values])\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "    edge_weights = torch.tensor(edges['weight'].values, dtype=torch.float)\n",
        "    g = Data(x=node_feature, edge_index=edge_index, edge_attr=edge_weights, y=edge_weights)\n",
        "    graphs.append(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0782b4a7-1de5-4df2-9590-8ad2c476123d",
      "metadata": {
        "id": "0782b4a7-1de5-4df2-9590-8ad2c476123d"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of graphs: {len(graphs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077331ff-6c29-431b-9b45-799e9bdd03e9",
      "metadata": {
        "id": "077331ff-6c29-431b-9b45-799e9bdd03e9"
      },
      "source": [
        "# GNN-LSTM Layer Implemetation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1f92a2-55c4-4d64-86f7-16ca27409369",
      "metadata": {
        "id": "8d1f92a2-55c4-4d64-86f7-16ca27409369"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Parameter\n",
        "from torch_geometric.nn import ChebConv\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "class GConvLSTM(torch.nn.Module):\n",
        "    r\"\"\"An implementation of the Chebyshev Graph Convolutional Long Short Term Memory\n",
        "    Cell. For details see this paper: `\"Structured Sequence Modeling with Graph\n",
        "    Convolutional Recurrent Networks.\" <https://arxiv.org/abs/1612.07659>`_\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        out_channels (int): Number of output features.\n",
        "        K (int): Chebyshev filter size :math:`K`.\n",
        "        normalization (str, optional): The normalization scheme for the graph\n",
        "            Laplacian (default: :obj:`\"sym\"`):\n",
        "\n",
        "            1. :obj:`None`: No normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
        "\n",
        "            2. :obj:`\"sym\"`: Symmetric normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
        "            \\mathbf{D}^{-1/2}`\n",
        "\n",
        "            3. :obj:`\"rw\"`: Random-walk normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
        "\n",
        "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
        "            this operator in case the normalization is non-symmetric.\n",
        "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
        "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
        "            scalar/zero-dimensional tensor when operating on single graphs.\n",
        "            You can pre-compute :obj:`lambda_max` via the\n",
        "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        K: int,\n",
        "        normalization: str = \"sym\",\n",
        "        bias: bool = True,\n",
        "    ):\n",
        "        super(GConvLSTM, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.K = K\n",
        "        self.normalization = normalization\n",
        "        self.bias = bias\n",
        "        self._create_parameters_and_layers()\n",
        "        self._set_parameters()\n",
        "\n",
        "    def _create_input_gate_parameters_and_layers(self):\n",
        "\n",
        "        self.conv_x_i = ChebConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.conv_h_i = ChebConv(\n",
        "            in_channels=self.out_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.w_c_i = Parameter(torch.Tensor(1, self.out_channels))\n",
        "        self.b_i = Parameter(torch.Tensor(1, self.out_channels))\n",
        "\n",
        "    def _create_forget_gate_parameters_and_layers(self):\n",
        "\n",
        "        self.conv_x_f = ChebConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.conv_h_f = ChebConv(\n",
        "            in_channels=self.out_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.w_c_f = Parameter(torch.Tensor(1, self.out_channels))\n",
        "        self.b_f = Parameter(torch.Tensor(1, self.out_channels))\n",
        "\n",
        "    def _create_cell_state_parameters_and_layers(self):\n",
        "\n",
        "        self.conv_x_c = ChebConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.conv_h_c = ChebConv(\n",
        "            in_channels=self.out_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.b_c = Parameter(torch.Tensor(1, self.out_channels))\n",
        "\n",
        "    def _create_output_gate_parameters_and_layers(self):\n",
        "\n",
        "        self.conv_x_o = ChebConv(\n",
        "            in_channels=self.in_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.conv_h_o = ChebConv(\n",
        "            in_channels=self.out_channels,\n",
        "            out_channels=self.out_channels,\n",
        "            K=self.K,\n",
        "            normalization=self.normalization,\n",
        "            bias=self.bias,\n",
        "        )\n",
        "\n",
        "        self.w_c_o = Parameter(torch.Tensor(1, self.out_channels))\n",
        "        self.b_o = Parameter(torch.Tensor(1, self.out_channels))\n",
        "\n",
        "    def _create_parameters_and_layers(self):\n",
        "        self._create_input_gate_parameters_and_layers()\n",
        "        self._create_forget_gate_parameters_and_layers()\n",
        "        self._create_cell_state_parameters_and_layers()\n",
        "        self._create_output_gate_parameters_and_layers()\n",
        "\n",
        "    def _set_parameters(self):\n",
        "        glorot(self.w_c_i)\n",
        "        glorot(self.w_c_f)\n",
        "        glorot(self.w_c_o)\n",
        "        zeros(self.b_i)\n",
        "        zeros(self.b_f)\n",
        "        zeros(self.b_c)\n",
        "        zeros(self.b_o)\n",
        "\n",
        "    def _set_hidden_state(self, X, H):\n",
        "        if H is None:\n",
        "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
        "        return H\n",
        "\n",
        "    def _set_cell_state(self, X, C):\n",
        "        if C is None:\n",
        "            C = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
        "        return C\n",
        "\n",
        "    def _calculate_input_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
        "        I = self.conv_x_i(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        I = I + self.conv_h_i(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        I = I + (self.w_c_i * C)\n",
        "        I = I + self.b_i\n",
        "        I = torch.sigmoid(I)\n",
        "        return I\n",
        "\n",
        "    def _calculate_forget_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
        "        F = self.conv_x_f(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        F = F + self.conv_h_f(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        F = F + (self.w_c_f * C)\n",
        "        F = F + self.b_f\n",
        "        F = torch.sigmoid(F)\n",
        "        return F\n",
        "\n",
        "    def _calculate_cell_state(self, X, edge_index, edge_weight, H, C, I, F, lambda_max):\n",
        "        T = self.conv_x_c(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        T = T + self.conv_h_c(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        T = T + self.b_c\n",
        "        T = torch.tanh(T)\n",
        "        C = F * C + I * T\n",
        "        return C\n",
        "\n",
        "    def _calculate_output_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
        "        O = self.conv_x_o(X, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        O = O + self.conv_h_o(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
        "        O = O + (self.w_c_o * C)\n",
        "        O = O + self.b_o\n",
        "        O = torch.sigmoid(O)\n",
        "        return O\n",
        "\n",
        "    def _calculate_hidden_state(self, O, C):\n",
        "        H = O * torch.tanh(C)\n",
        "        return H\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        X: torch.FloatTensor,\n",
        "        edge_index: torch.LongTensor,\n",
        "        edge_weight: torch.FloatTensor = None,\n",
        "        H: torch.FloatTensor = None,\n",
        "        C: torch.FloatTensor = None,\n",
        "        lambda_max: torch.Tensor = None,\n",
        "    ) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass. If edge weights are not present the forward pass\n",
        "        defaults to an unweighted graph. If the hidden state and cell state\n",
        "        matrices are not present when the forward pass is called these are\n",
        "        initialized with zeros.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
        "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
        "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
        "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
        "            * **C** *(PyTorch Float Tensor, optional)* - Cell state matrix for all nodes.\n",
        "            * **lambda_max** *(PyTorch Tensor, optional but mandatory if normalization is not sym)* - Largest eigenvalue of Laplacian.\n",
        "\n",
        "        Return types:\n",
        "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
        "            * **C** *(PyTorch Float Tensor)* - Cell state matrix for all nodes.\n",
        "        \"\"\"\n",
        "        H = self._set_hidden_state(X, H)\n",
        "        C = self._set_cell_state(X, C)\n",
        "        I = self._calculate_input_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
        "        F = self._calculate_forget_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
        "        C = self._calculate_cell_state(X, edge_index, edge_weight, H, C, I, F, lambda_max)\n",
        "        O = self._calculate_output_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
        "        H = self._calculate_hidden_state(O, C)\n",
        "        return H, C"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d94cd12c",
      "metadata": {
        "id": "d94cd12c"
      },
      "source": [
        "# Temporal Link Predictor Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rVlPlbnt5GIB",
      "metadata": {
        "id": "rVlPlbnt5GIB"
      },
      "outputs": [],
      "source": [
        "class TemporalGNN(torch.nn.Module):\n",
        "    def __init__(self, num_nodes, node_features, hidden_channels, output_channels):\n",
        "        super(TemporalGNN, self).__init__()\n",
        "        self.recurrent = GConvLSTM(node_features, hidden_channels, 3)\n",
        "        self.linear = torch.nn.Linear(hidden_channels, output_channels)\n",
        "        self.edge_mlp = torch.nn.Sequential(\n",
        "                torch.nn.Linear(2 * output_channels, hidden_channels),\n",
        "                torch.nn.ReLU(),\n",
        "                torch.nn.Linear(hidden_channels, 1)\n",
        "            )\n",
        "\n",
        "    def forward(self, seq):\n",
        "        H, C = None, None\n",
        "        for i in range(len(seq)):\n",
        "            x = seq[i].x\n",
        "            edge_index = seq[i].edge_index\n",
        "            edge_attr = seq[i].edge_attr\n",
        "            H, C = self.recurrent(x, edge_index, edge_attr, H, C)\n",
        "\n",
        "        H = F.relu(H)\n",
        "        H = self.linear(H)\n",
        "        return F.log_softmax(H, dim=1)\n",
        "\n",
        "    def predict_edge_weight(self, node_embeddings, edge_index):\n",
        "        src, dst = edge_index\n",
        "        edge_features = torch.cat([node_embeddings[src], node_embeddings[dst]], dim=1)\n",
        "        probs = self.edge_mlp(edge_features)\n",
        "        probs = torch.sigmoid(probs)\n",
        "        return probs.squeeze()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187b6576",
      "metadata": {
        "id": "187b6576"
      },
      "source": [
        "# Initializing model and creating train-test splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b4b29a-b6e8-46e6-9cf1-876266b61970",
      "metadata": {
        "id": "c9b4b29a-b6e8-46e6-9cf1-876266b61970"
      },
      "outputs": [],
      "source": [
        "node_dim = graphs[0].x.shape[1]\n",
        "num_nodes = graphs[0].x.shape[0]\n",
        "hidden_channels = 64\n",
        "output_channels = 64\n",
        "learning_rate = 0.0001\n",
        "epochs = 20\n",
        "time_window = 10\n",
        "weight_decay = 0.0001\n",
        "\n",
        "model = TemporalGNN(num_nodes, node_dim, hidden_channels, output_channels)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
      "metadata": {
        "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import copy\n",
        "\n",
        "def create_sequences(data, time_step):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        Y.append(data[i + time_step])\n",
        "    return X, Y\n",
        "\n",
        "x, y = create_sequences(graphs, time_window)\n",
        "\n",
        "split_index = int(len(x) * 0.8)\n",
        "\n",
        "x_train, x_test = copy.deepcopy(x[:split_index]), copy.deepcopy(x[split_index:])\n",
        "y_train, y_test = copy.deepcopy(y[:split_index]), copy.deepcopy(y[split_index:])\n",
        "\n",
        "print(\"Size of x_train:\", len(x_train))\n",
        "print(\"Size of x_test:\", len(x_test))\n",
        "print(\"Size of y_train:\", len(y_train))\n",
        "print(\"Size of y_test:\", len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eff7b51-e82d-4be9-941e-39dee26efc4e",
      "metadata": {
        "id": "0eff7b51-e82d-4be9-941e-39dee26efc4e"
      },
      "source": [
        "# Training Loop to generate edges for N+1th graph using last N graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dac0b90-096d-4529-944e-16ddca73fa56",
      "metadata": {
        "id": "9dac0b90-096d-4529-944e-16ddca73fa56"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "def add_negative_samples(data):\n",
        "    num_pos_samples = data.edge_index.size(1)\n",
        "    num_neg_samples = num_pos_samples\n",
        "    neg_edge_index = negative_sampling(data.edge_index, num_nodes=data.num_nodes, num_neg_samples=num_neg_samples)\n",
        "    pos_weights = torch.ones(num_pos_samples, device=data.edge_index.device)\n",
        "    neg_weights = torch.zeros(num_neg_samples, device=data.edge_index.device)\n",
        "\n",
        "    data.edge_index = torch.cat([data.edge_index, neg_edge_index], dim=1)\n",
        "    data.y = torch.cat([pos_weights, neg_weights])\n",
        "    data.edge_attr = torch.cat([data.edge_attr, neg_weights])\n",
        "\n",
        "    perm = torch.randperm(data.edge_index.size(1))\n",
        "\n",
        "    data.edge_index = data.edge_index[:, perm]\n",
        "    data.edge_attr = data.edge_attr[perm]\n",
        "    data.y = data.y[perm]\n",
        "\n",
        "    return data\n",
        "\n",
        "for i in range(len(y_train)):\n",
        "    y_train[i] = add_negative_samples(y_train[i])\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    y_test[i] = add_negative_samples(y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a551bd8-44b4-495f-b587-cbc84fac52a0",
      "metadata": {
        "id": "8a551bd8-44b4-495f-b587-cbc84fac52a0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "train_losses = []\n",
        "val_accuracies_combined = []\n",
        "val_accuracies_presence = []\n",
        "val_accuracies_absence = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for i in range(len(x_train)):\n",
        "        optimizer.zero_grad()\n",
        "        node_embeddings = model(x_train[i])\n",
        "        probs = model.predict_edge_weight(node_embeddings, y_train[i].edge_index)\n",
        "        loss = criterion(probs, y_train[i].y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(x_train)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    total_correct_presence = 0\n",
        "    total_correct_absence = 0\n",
        "    total_presence = 0\n",
        "    total_absence = 0\n",
        "    total_correct = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(x_test)):\n",
        "            node_embeddings = model(x_test[i])\n",
        "            probs = model.predict_edge_weight(node_embeddings, y_test[i].edge_index)\n",
        "            predictions = (probs > 0.5).int()\n",
        "\n",
        "            correct_presence = ((predictions == y_test[i].y) & (y_test[i].y == 1)).sum().item()\n",
        "            correct_absence = ((predictions == y_test[i].y) & (y_test[i].y == 0)).sum().item()\n",
        "\n",
        "            total_correct_presence += correct_presence\n",
        "            total_correct_absence += correct_absence\n",
        "\n",
        "            total_presence += (y_test[i].y == 1).sum().item()\n",
        "            total_absence += (y_test[i].y == 0).sum().item()\n",
        "\n",
        "            total_correct += (predictions == y_test[i].y).sum().item()\n",
        "            total_predictions += y_test[i].y.size(0)\n",
        "\n",
        "    val_accuracy_presence = total_correct_presence / total_presence if total_presence > 0 else 0\n",
        "    val_accuracy_absence = total_correct_absence / total_absence if total_absence > 0 else 0\n",
        "    val_accuracy_combined = total_correct / total_predictions if total_predictions > 0 else 0\n",
        "\n",
        "    val_accuracies_presence.append(val_accuracy_presence)\n",
        "    val_accuracies_absence.append(val_accuracy_absence)\n",
        "    val_accuracies_combined.append(val_accuracy_combined)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {avg_train_loss:.4f}, Val Accuracy (Combined): {val_accuracy_combined:.4f}, Val Accuracy (Presence): {val_accuracy_presence:.4f}, Val Accuracy (Absence): {val_accuracy_absence:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'test_model.pth')"
      ],
      "metadata": {
        "id": "GtG0Wg9B8Vz4"
      },
      "id": "GtG0Wg9B8Vz4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gcsfs\n",
        "\n",
        "path = 'gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/model_weights/tgn_complete_model.pth'\n",
        "fs = gcsfs.GCSFileSystem()\n",
        "\n",
        "with fs.open(path, 'rb') as f:\n",
        "    state_dict = torch.load(f)\n",
        "\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "MthDlchwzwzW"
      },
      "id": "MthDlchwzwzW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "549dcaf8-e707-4461-8111-95ea33cc9c05",
      "metadata": {
        "id": "549dcaf8-e707-4461-8111-95ea33cc9c05"
      },
      "source": [
        "# Predicting edges of N+1th graph given last N graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec62ff0-4acf-499a-84cf-f6575281fc01",
      "metadata": {
        "id": "7ec62ff0-4acf-499a-84cf-f6575281fc01"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "presence_accuracy = 0\n",
        "absence_accuracy = 0\n",
        "num_tests = len(x_test)\n",
        "\n",
        "presence_count = 0\n",
        "absence_count = 0\n",
        "\n",
        "for i in range(num_tests):\n",
        "    with torch.no_grad():\n",
        "        node_embeddings = model(x_test[i])\n",
        "        probs = model.predict_edge_weight(node_embeddings, y_test[i].edge_index)\n",
        "\n",
        "    threshold = 0.5\n",
        "    yhat = (probs > threshold).int()\n",
        "    y_true = y_test[i].y\n",
        "\n",
        "    presence_mask = y_true == 1\n",
        "    absence_mask = y_true == 0\n",
        "\n",
        "    if presence_mask.sum().item() > 0:\n",
        "        presence_accuracy += accuracy_score(y_true[presence_mask].numpy().astype(int), yhat[presence_mask].numpy().astype(int))\n",
        "        presence_count += 1\n",
        "\n",
        "    if absence_mask.sum().item() > 0:\n",
        "        absence_accuracy += accuracy_score(y_true[absence_mask].numpy().astype(int), yhat[absence_mask].numpy().astype(int))\n",
        "        absence_count += 1\n",
        "\n",
        "average_presence_accuracy = presence_accuracy / presence_count if presence_count > 0 else 0\n",
        "average_absence_accuracy = absence_accuracy / absence_count if absence_count > 0 else 0\n",
        "\n",
        "average_presence_accuracy_percentage = round(average_presence_accuracy * 100)\n",
        "average_absence_accuracy_percentage = round(average_absence_accuracy * 100)\n",
        "\n",
        "print(f'Average Presence Accuracy: {average_presence_accuracy_percentage}%')\n",
        "print(f'Average Absence Accuracy: {average_absence_accuracy_percentage}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b38a80-4647-4431-9e7d-4f8b426c9246",
      "metadata": {
        "id": "55b38a80-4647-4431-9e7d-4f8b426c9246"
      },
      "outputs": [],
      "source": [
        "def calculate_confusion_matrix(total_positive, total_negative, accuracy_presence, accuracy_absence):\n",
        "    TP = accuracy_presence * total_positive\n",
        "    TN = accuracy_absence * total_negative\n",
        "    FP = total_negative - TN\n",
        "    FN = total_positive - TP\n",
        "\n",
        "    return TP, TN, FP, FN\n",
        "\n",
        "def calculate_precision_recall(TP, FP, FN):\n",
        "    if TP + FP == 0:\n",
        "        Precision = 0\n",
        "    else:\n",
        "        Precision = TP / (TP + FP)\n",
        "\n",
        "    if TP + FN == 0:\n",
        "        Recall = 0\n",
        "    else:\n",
        "        Recall = TP / (TP + FN)\n",
        "\n",
        "    return Precision, Recall\n",
        "\n",
        "total_samples = sum(len(x.y) for x in y_test)\n",
        "total_positive = total_samples // 2\n",
        "total_negative = total_positive\n",
        "accuracy_presence = average_presence_accuracy\n",
        "accuracy_absence = average_absence_accuracy\n",
        "\n",
        "TP, TN, FP, FN = calculate_confusion_matrix(total_positive, total_negative, accuracy_presence, accuracy_absence)\n",
        "Precision, Recall = calculate_precision_recall(TP, FP, FN)\n",
        "\n",
        "print(f\"Precision: {Precision}\")\n",
        "print(f\"Recall: {Recall}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "TGN_trend_predictor_end_to_end.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
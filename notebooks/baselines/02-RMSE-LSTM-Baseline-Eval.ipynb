{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "MJouDrUr44kn",
      "metadata": {
        "id": "MJouDrUr44kn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721962391960,
          "user_tz": 240,
          "elapsed": 162,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "import xxhash"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780a3e3d",
      "metadata": {
        "id": "780a3e3d"
      },
      "source": [
        "# Loading data from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "pLW3HgyQ2CFP",
      "metadata": {
        "id": "pLW3HgyQ2CFP",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721962977968,
          "user_tz": 240,
          "elapsed": 159,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def load_data(year, data_dir, percentile=0.0):\n",
        "    edges = pd.read_parquet(f'{data_dir}/{year}/{year}_edges.parquet', engine='pyarrow')\n",
        "    nodes = pd.read_parquet(f'{data_dir}/{year}/{year}_nodes.parquet', engine='pyarrow')\n",
        "    weight_threshold = edges['weight'].quantile(percentile)\n",
        "    filtered_edges = edges[edges['weight'] >= weight_threshold]\n",
        "    return filtered_edges, nodes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/parquet_data\"\n",
        "years = range(1980, 2023)\n",
        "\n",
        "all_node_ids = set()\n",
        "id_to_label = {}\n",
        "total = 0\n",
        "for i in years:\n",
        "    e, n = load_data(i, data_dir)\n",
        "    total = total + len(e.drop_duplicates())\n",
        "    all_node_ids = all_node_ids.union(set(n['node_id'].tolist()))\n",
        "    keys , vals = n['node_id'].tolist() , n['node_label'].tolist()\n",
        "    entries = {key: value for key, value in zip(keys, vals)}\n",
        "    id_to_label.update(entries)"
      ],
      "metadata": {
        "id": "tHTJXOlEbizF",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721962857901,
          "user_tz": 240,
          "elapsed": 51475,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "tHTJXOlEbizF",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_dir = \"gs://datasets-dev-ded86f66/benchmarks/scientific_trend_prediction/parquet_data\"\n",
        "years = range(1980, 2023)\n",
        "\n",
        "all_node_ids = set()\n",
        "id_to_label = {}\n",
        "total_unique_entries = 0\n",
        "\n",
        "all_edges = []\n",
        "all_nodes = []\n",
        "\n",
        "for year in years:\n",
        "    e, n = load_data(year, data_dir)\n",
        "    all_edges.append(e)\n",
        "    all_nodes.append(n)\n",
        "\n",
        "# Concatenate all dataframes\n",
        "all_edges_df = pd.concat(all_edges, ignore_index=True)\n",
        "all_nodes_df = pd.concat(all_nodes, ignore_index=True)\n",
        "\n",
        "# Drop duplicates to get unique entries\n",
        "unique_edges_df = all_edges_df.drop_duplicates()\n",
        "unique_nodes_df = all_nodes_df.drop_duplicates()\n",
        "\n",
        "# Update total unique entries\n",
        "total_unique_entries = len(unique_edges_df)\n",
        "\n",
        "# Update all_node_ids set\n",
        "all_node_ids.update(unique_nodes_df['node_id'].tolist())\n",
        "\n",
        "# Update id_to_label dictionary\n",
        "keys = unique_nodes_df['node_id'].tolist()\n",
        "vals = unique_nodes_df['node_label'].tolist()\n",
        "id_to_label.update(dict(zip(keys, vals)))\n",
        "\n",
        "print(f\"Total unique entries: {total_unique_entries}\")\n",
        "print(f\"Total unique node IDs: {len(all_node_ids)}\")\n",
        "print(f\"Total entries in id_to_label: {len(id_to_label)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2TAZeoX9SMT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721963244746,
          "user_tz": 240,
          "elapsed": 51827,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "76e84c2e-c2a9-41f0-c055-f11e240164cd"
      },
      "id": "A2TAZeoX9SMT",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique entries: 35268983\n",
            "Total unique node IDs: 36076\n",
            "Total entries in id_to_label: 36076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import networkx as nx\n",
        "\n",
        "def featurizer(edges, node_ids, id_to_label):\n",
        "    label_order = ['phenotype', 'gene', 'compound']\n",
        "    label_to_index = {label: i for i, label in enumerate(label_order)}\n",
        "\n",
        "    node_features = np.zeros((len(node_ids), 3), dtype=float)\n",
        "    out_degree_count = {node: {label: 0 for label in label_order} for node in node_ids}\n",
        "\n",
        "    for src, dest in zip(edges['source_id'], edges['destination_id']):\n",
        "        dest_label = id_to_label[dest]\n",
        "        out_degree_count[src][dest_label] += 1\n",
        "\n",
        "    for i, node in enumerate(node_ids):\n",
        "        node_feature_vector = [out_degree_count[node][label] for label in label_order]\n",
        "        node_features[i] = node_feature_vector\n",
        "\n",
        "    return torch.tensor(node_features, dtype=torch.float)"
      ],
      "metadata": {
        "id": "mhrucsbpblAx",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941857394,
          "user_tz": 240,
          "elapsed": 146,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "mhrucsbpblAx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_ids = list(all_node_ids)\n",
        "node_id_to_index = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
        "\n",
        "graphs = []\n",
        "\n",
        "for year in years:\n",
        "    edges, _ = load_data(year, data_dir)\n",
        "    node_feature = featurizer(edges, node_ids, id_to_label)\n",
        "    edge_index = np.array([edges['source_id'].map(node_id_to_index).values,\n",
        "                           edges['destination_id'].map(node_id_to_index).values])\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "    edge_weights = torch.tensor(edges['weight'].values, dtype=torch.float)\n",
        "    g = Data(x=node_feature, edge_index=edge_index, edge_attr=edge_weights, y=edge_weights)\n",
        "    graphs.append(g)"
      ],
      "metadata": {
        "id": "OaK02gPxbo1m",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941901791,
          "user_tz": 240,
          "elapsed": 44399,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "OaK02gPxbo1m",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ab6ff68a-97ae-4dfa-9331-562ef5323120",
      "metadata": {
        "id": "ab6ff68a-97ae-4dfa-9331-562ef5323120"
      },
      "source": [
        "# Normalizing edge weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "94ef828e-58f8-46cc-bc9e-10a5ef80223b",
      "metadata": {
        "id": "94ef828e-58f8-46cc-bc9e-10a5ef80223b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941901791,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def normalize_edge_weights_min_max(graph_list):\n",
        "    all_weights = []\n",
        "    for graph in graph_list:\n",
        "        all_weights.extend(graph.edge_attr.view(-1).tolist())\n",
        "\n",
        "    min_weight = min(all_weights)\n",
        "    max_weight = max(all_weights)\n",
        "\n",
        "    for graph in graph_list:\n",
        "        edge_attr_normalized = (graph.edge_attr - min_weight) / (max_weight - min_weight)\n",
        "        graph.edge_attr = edge_attr_normalized\n",
        "        graph.y = edge_attr_normalized\n",
        "\n",
        "    return graph_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a4a313e4-60fe-4b17-8c47-c383fc3d5968",
      "metadata": {
        "id": "a4a313e4-60fe-4b17-8c47-c383fc3d5968",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941902082,
          "user_tz": 240,
          "elapsed": 292,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "graphs = normalize_edge_weights_min_max(graphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0782b4a7-1de5-4df2-9590-8ad2c476123d",
      "metadata": {
        "id": "0782b4a7-1de5-4df2-9590-8ad2c476123d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941902083,
          "user_tz": 240,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "665e22df-b437-4530-ba39-2b7539146097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 44\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of graphs: {len(graphs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
      "metadata": {
        "id": "78df504e-a7ef-4e2e-be78-dc7718ca8e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941902243,
          "user_tz": 240,
          "elapsed": 162,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e15698ec-41e0-42e1-9b29-27a675405fa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of x_train: 26\n",
            "Size of x_test: 7\n",
            "Size of y_train: 26\n",
            "Size of y_test: 7\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_sequences(data, time_step):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        Y.append(data[i + time_step])\n",
        "    return X, Y\n",
        "\n",
        "x, y = create_sequences(graphs, 10)\n",
        "\n",
        "split_index = int(len(x) * 0.8)\n",
        "\n",
        "x_train, x_test = x[:split_index], x[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "print(\"Size of x_train:\", len(x_train))\n",
        "print(\"Size of x_test:\", len(x_test))\n",
        "print(\"Size of y_train:\", len(y_train))\n",
        "print(\"Size of y_test:\", len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93688385-dd4b-4d36-9998-bc9e69bc51a2",
      "metadata": {
        "id": "93688385-dd4b-4d36-9998-bc9e69bc51a2"
      },
      "source": [
        "# LSTM Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "57df6e0c-ad3e-4df5-9eb5-7d3dcd443721",
      "metadata": {
        "id": "57df6e0c-ad3e-4df5-9eb5-7d3dcd443721",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941904918,
          "user_tz": 240,
          "elapsed": 2676,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c7a68f09-e096-48a0-9a1f-0ea1ba17c494",
      "metadata": {
        "id": "c7a68f09-e096-48a0-9a1f-0ea1ba17c494",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941904918,
          "user_tz": 240,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "def concatenate_edge_weights(grphs):\n",
        "    reference_edge_index = grphs[0].edge_index\n",
        "    reference_edge_attr = grphs[0].edge_attr\n",
        "\n",
        "    edge_dict = {}\n",
        "    for i in range(reference_edge_index.shape[1]):\n",
        "        edge = tuple(reference_edge_index[:, i].numpy())\n",
        "        edge_dict[edge] = [reference_edge_attr[i].item()]\n",
        "\n",
        "    for grph in grphs[1:]:\n",
        "        edge_attr = grph.edge_attr\n",
        "        edge_index = grph.edge_index\n",
        "\n",
        "        for i in range(edge_index.shape[1]):\n",
        "            edge = tuple(edge_index[:, i].numpy())\n",
        "            if edge in edge_dict:\n",
        "                edge_dict[edge].append(edge_attr[i].item())\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    max_len = len(grphs)\n",
        "\n",
        "    concatenated_weights = []\n",
        "    for edge, weights in edge_dict.items():\n",
        "        while len(weights) < max_len:\n",
        "            weights.append(0.0)\n",
        "        concatenated_weights.append(np.array(weights))\n",
        "\n",
        "    concatenated_weights_array = np.array(concatenated_weights)\n",
        "\n",
        "    return concatenated_weights_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def concatenate_edge_weights(grphs):\n",
        "    reference_edge_index = grphs[0].edge_index\n",
        "    reference_edge_attr = grphs[0].edge_attr\n",
        "\n",
        "    edge_dict = {}\n",
        "    for i in range(reference_edge_index.shape[1]):\n",
        "        edge = tuple(reference_edge_index[:, i].numpy())\n",
        "        edge_dict[edge] = [reference_edge_attr[i].item()]\n",
        "\n",
        "    max_len = len(grphs)\n",
        "\n",
        "    for grph in grphs[1:]:\n",
        "        edge_attr = grph.edge_attr\n",
        "        edge_index = grph.edge_index\n",
        "\n",
        "        current_edges = {tuple(edge_index[:, i].numpy()): edge_attr[i].item() for i in range(edge_index.shape[1])}\n",
        "\n",
        "        for edge in edge_dict.keys():\n",
        "            if edge in current_edges:\n",
        "                edge_dict[edge].append(current_edges[edge])\n",
        "            else:\n",
        "                edge_dict[edge].append(0.0)\n",
        "\n",
        "    concatenated_weights = [np.array(weights) for weights in edge_dict.values()]\n",
        "    concatenated_weights_array = np.array(concatenated_weights)\n",
        "\n",
        "    return concatenated_weights_array"
      ],
      "metadata": {
        "id": "CmsT3bQ5MfjW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721941904918,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "CmsT3bQ5MfjW",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "13a3e302-52d6-4113-8c35-ac4d6609e011",
      "metadata": {
        "id": "13a3e302-52d6-4113-8c35-ac4d6609e011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942264480,
          "user_tz": 240,
          "elapsed": 359564,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0b4ba6e6-329a-45bd-af51-5caa105a4304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 26/26 [05:59<00:00, 13.83s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "seq_data_batchs = []\n",
        "\n",
        "for i in tqdm(range(len(x_train)), desc=\"Processing batches\"):\n",
        "    weights = concatenate_edge_weights([y_train[i]] + x_train[i])\n",
        "    seq_data_batchs.append(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a77e7747-2bf2-460e-ac6e-f4b604af9491",
      "metadata": {
        "id": "a77e7747-2bf2-460e-ac6e-f4b604af9491",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942264480,
          "user_tz": 240,
          "elapsed": 12,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "k = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "779c0b6d-9797-4648-9cee-3a01ad190a11",
      "metadata": {
        "id": "779c0b6d-9797-4648-9cee-3a01ad190a11",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942301635,
          "user_tz": 240,
          "elapsed": 37156,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "input_dim = k\n",
        "time_step = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(time_step, input_dim)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(input_dim,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "for batch in seq_data_batchs:\n",
        "    X, Y = batch[:, 1:], batch[:, 0]\n",
        "\n",
        "    for j in range(0, X.shape[0], k):\n",
        "        x, y = X[j:j+k, :], Y[j:j+k]\n",
        "\n",
        "        if len(x) < k:\n",
        "            continue\n",
        "\n",
        "        x = x.transpose(1, 0)\n",
        "        y = y.reshape(1, -1)\n",
        "\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "\n",
        "        model.fit(x, y, epochs=3, batch_size=1,verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba1b195-eba8-4470-8e21-478d53f7ba9e",
      "metadata": {
        "id": "bba1b195-eba8-4470-8e21-478d53f7ba9e"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "91293c52-4f52-4ad5-a292-49807d400872",
      "metadata": {
        "id": "91293c52-4f52-4ad5-a292-49807d400872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942515019,
          "user_tz": 240,
          "elapsed": 213385,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0b316081-9987-40cd-c7c8-3762dc39b8fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing batches: 100%|██████████| 7/7 [03:33<00:00, 30.49s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "test_seq_batches = []\n",
        "\n",
        "for i in tqdm(range(len(x_test)), desc=\"Processing batches\"):\n",
        "    weights = concatenate_edge_weights([y_test[i]] + x_test[i])\n",
        "    test_seq_batches.append(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4bcb6729-6869-4f8c-ac84-a42acc02abae",
      "metadata": {
        "id": "4bcb6729-6869-4f8c-ac84-a42acc02abae",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942528384,
          "user_tz": 240,
          "elapsed": 13367,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "all_true_values = []\n",
        "all_predictions = []\n",
        "\n",
        "for batch in test_seq_batches:\n",
        "    X, Y = batch[:, 1:], batch[:, 0]\n",
        "\n",
        "    for j in range(0, X.shape[0], k):\n",
        "        x, y = X[j:j+k, :], Y[j:j+k]\n",
        "\n",
        "        if len(x) < k:\n",
        "            continue\n",
        "\n",
        "        x = x.transpose(1, 0)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        y = y.reshape(-1, 1)\n",
        "\n",
        "        yhat = model.predict(x,verbose=0)\n",
        "        yhat = yhat.reshape(-1, 1)\n",
        "\n",
        "        all_true_values.extend(y)\n",
        "        all_predictions.extend(yhat)\n",
        "\n",
        "all_true_values = np.array(all_true_values)\n",
        "all_predictions = np.array(all_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(all_true_values, all_predictions)"
      ],
      "metadata": {
        "id": "U9IxOPXvSu3K",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942528384,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "U9IxOPXvSu3K",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U61LO8xDu04C",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1721942728817,
          "user_tz": 240,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2735c3bb-2093-43e4-9f63-9c4b47f97fce"
      },
      "id": "U61LO8xDu04C",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0002880302120263512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHVHG0W1yNyf"
      },
      "id": "cHVHG0W1yNyf",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "RSME_lstm_baseline.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}